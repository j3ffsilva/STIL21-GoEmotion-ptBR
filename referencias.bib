

@article{Devlin2018,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5% (7.7% point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
eprint = {1810.04805},
file = {:Users/diogocortiz/Library/Application Support/Mendeley Desktop/Downloaded/Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:pdf},
mendeley-groups = {NLP},
month = {oct},
title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
url = {http://arxiv.org/abs/1810.04805},
year = {2018}
}

@book{Rosalind2000,
address = {Cambridge},
author = {Rosalind, Picard},
mendeley-groups = {Affective Computing},
publisher = {MIT Press},
title = {{Affective Computing}},
year = {2000}
}
@article{Drus2019,
author = {Drus, Zulfadzli and Khalid, Haliyana},
doi = {10.1016/j.procs.2019.11.174},
issn = {18770509},
journal = {Procedia Computer Science},
mendeley-groups = {Affective Computing},
pages = {707--714},
title = {{Sentiment Analysis in Social Media and Its Application: Systematic Literature Review}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S187705091931885X},
volume = {161},
year = {2019}
}
@article{Ekman1992,
author = {Ekman, Paul},
doi = {10.1080/02699939208411068},
issn = {0269-9931},
journal = {Cognition and Emotion},
mendeley-groups = {Affective Computing},
month = {may},
number = {3-4},
pages = {169--200},
title = {{An argument for basic emotions}},
url = {https://www.tandfonline.com/doi/full/10.1080/02699939208411068},
volume = {6},
year = {1992}
}
@article{Batbaatar2019,
author = {Batbaatar, Erdenebileg and Li, Meijing and Ryu, Keun Ho},
doi = {10.1109/ACCESS.2019.2934529},
issn = {2169-3536},
journal = {IEEE Access},
mendeley-groups = {Affective Computing},
pages = {111866--111878},
title = {{Semantic-Emotion Neural Network for Emotion Recognition From Text}},
url = {https://ieeexplore.ieee.org/document/8794541/},
volume = {7},
year = {2019}
}
@inproceedings{Sosea2020,
address = {Stroudsburg, PA, USA},
author = {Sosea, Tiberiu and Caragea, Cornelia},
booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
doi = {10.18653/v1/2020.emnlp-main.715},
mendeley-groups = {Affective Computing},
pages = {8892--8904},
publisher = {Association for Computational Linguistics},
title = {{CancerEmo: A Dataset for Fine-Grained Emotion Detection}},
url = {https://www.aclweb.org/anthology/2020.emnlp-main.715},
year = {2020}
}

@article{Barrett2016,
author = {Barrett, Lisa Feldman},
doi = {10.1093/scan/nsw154},
file = {:Users/diogocortiz/Desktop/nsw154.pdf:pdf},
issn = {1749-5016},
journal = {Social Cognitive and Affective Neuroscience},
mendeley-groups = {Affective Computing/Affective Science},
month = {oct},
pages = {nsw154},
title = {{The theory of constructed emotion: an active inference account of interoception and categorization}},
url = {https://academic.oup.com/scan/article-lookup/doi/10.1093/scan/nsw154},
year = {2016}
}
@article{Cowen2021,
author = {Cowen, Alan S. and Keltner, Dacher},
doi = {10.1016/j.tics.2020.11.004},
file = {:Users/diogocortiz/Desktop/1-s2.0-S136466132030276X-main.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
mendeley-groups = {Affective Computing/Affective Science},
month = {feb},
number = {2},
pages = {124--136},
title = {{Semantic Space Theory: A Computational Approach to Emotion}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S136466132030276X},
volume = {25},
year = {2021}
}

@inproceedings{Demszky2020,
address = {Stroudsburg, PA, USA},
author = {Demszky, Dorottya and Movshovitz-Attias, Dana and Ko, Jeongwoo and Cowen, Alan and Nemade, Gaurav and Ravi, Sujith},
booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
doi = {10.18653/v1/2020.acl-main.372},
file = {:Users/diogocortiz/Desktop/2020.acl-main.372.pdf:pdf},
mendeley-groups = {Affective Computing/Affective Science},
pages = {4040--4054},
publisher = {Association for Computational Linguistics},
title = {{GoEmotions: A Dataset of Fine-Grained Emotions}},
url = {https://www.aclweb.org/anthology/2020.acl-main.372},
year = {2020}
}
@article{Pereira2021,
author = {Pereira, Denilson Alves},
doi = {10.1007/s10462-020-09870-1},
issn = {0269-2821},
journal = {Artificial Intelligence Review},
mendeley-groups = {Affective Computing},
month = {feb},
number = {2},
pages = {1087--1115},
title = {{A survey of sentiment analysis in the Portuguese language}},
url = {https://link.springer.com/10.1007/s10462-020-09870-1},
volume = {54},
year = {2021}
}


archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
eprint = {1810.04805},
file = {:Users/diogocortiz/Library/Application Support/Mendeley Desktop/Downloaded/Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:pdf},
mendeley-groups = {NLP},
month = {oct},
title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
url = {http://arxiv.org/abs/1810.04805},
year = {2018}
}

@incollection{Bertimbau,
author = {Souza, F{\'{a}}bio and Nogueira, Rodrigo and Lotufo, Roberto},
doi = {10.1007/978-3-030-61377-8_28},
mendeley-groups = {NLP},
pages = {403--417},
title = {{BERTimbau: Pretrained BERT Models for Brazilian Portuguese}},
url = {http://link.springer.com/10.1007/978-3-030-61377-8_28},
year = {2020}
}









